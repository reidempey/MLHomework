{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Visualization libraries\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "matplotlib.style.use('fivethirtyeight')\n",
    "five_thirty_eight = [\"#30a2da\",\"#fc4f30\",\"#e5ae38\",\"#6d904f\",\"#8b8b8b\",]\n",
    "sns.set_palette(five_thirty_eight)\n",
    "%matplotlib inline\n",
    "\n",
    "# Silence deprecation warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Modeling, validation, and other SKLearn modules\n",
    "from sklearn.preprocessing import Imputer, StandardScaler\n",
    "from sklearn.model_selection import train_test_split, learning_curve, GridSearchCV, RandomizedSearchCV, cross_val_score, ShuffleSplit\n",
    "from sklearn.metrics import f1_score, roc_curve, classification_report, confusion_matrix, make_scorer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\reide\\Jupyter Notebooks\\Project\\Geographical Original of Music\\default_plus_chromatic_features_1059_tracks.txt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'C:/Users/reide/Jupyter Notebooks/Project/Geographical Original of Music/default_plus_chromatic_features_1059_tracks.txt'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = r'C:\\Users\\reide\\Jupyter Notebooks\\Project\\Geographical Original of Music\\default_plus_chromatic_features_1059_tracks.txt'\n",
    "print(file_path)\n",
    "file_path.replace('\\\\', '/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "music_df = pd.read_csv('C:/Users/reide/Jupyter Notebooks/Project/Geographical Original of Music/default_plus_chromatic_features_1059_tracks.txt', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>108</th>\n",
       "      <th>109</th>\n",
       "      <th>110</th>\n",
       "      <th>111</th>\n",
       "      <th>112</th>\n",
       "      <th>113</th>\n",
       "      <th>114</th>\n",
       "      <th>115</th>\n",
       "      <th>116</th>\n",
       "      <th>117</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.161286</td>\n",
       "      <td>7.835325</td>\n",
       "      <td>2.911583</td>\n",
       "      <td>0.984049</td>\n",
       "      <td>-1.499546</td>\n",
       "      <td>-2.094097</td>\n",
       "      <td>0.576000</td>\n",
       "      <td>-1.205671</td>\n",
       "      <td>1.849122</td>\n",
       "      <td>-0.425598</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.364194</td>\n",
       "      <td>-0.364194</td>\n",
       "      <td>-0.364194</td>\n",
       "      <td>-0.364194</td>\n",
       "      <td>-0.364194</td>\n",
       "      <td>-0.364194</td>\n",
       "      <td>-0.364194</td>\n",
       "      <td>-0.364194</td>\n",
       "      <td>-15.75</td>\n",
       "      <td>-47.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.225763</td>\n",
       "      <td>-0.094169</td>\n",
       "      <td>-0.603646</td>\n",
       "      <td>0.497745</td>\n",
       "      <td>0.874036</td>\n",
       "      <td>0.290280</td>\n",
       "      <td>-0.077659</td>\n",
       "      <td>-0.887385</td>\n",
       "      <td>0.432062</td>\n",
       "      <td>-0.093963</td>\n",
       "      <td>...</td>\n",
       "      <td>0.936616</td>\n",
       "      <td>0.936616</td>\n",
       "      <td>0.936616</td>\n",
       "      <td>0.936616</td>\n",
       "      <td>0.936616</td>\n",
       "      <td>0.936616</td>\n",
       "      <td>0.936616</td>\n",
       "      <td>0.936616</td>\n",
       "      <td>14.91</td>\n",
       "      <td>-23.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.692525</td>\n",
       "      <td>-0.517801</td>\n",
       "      <td>-0.788035</td>\n",
       "      <td>1.214351</td>\n",
       "      <td>-0.907214</td>\n",
       "      <td>0.880213</td>\n",
       "      <td>0.406899</td>\n",
       "      <td>-0.694895</td>\n",
       "      <td>-0.901869</td>\n",
       "      <td>-1.701574</td>\n",
       "      <td>...</td>\n",
       "      <td>0.603755</td>\n",
       "      <td>0.603755</td>\n",
       "      <td>0.603755</td>\n",
       "      <td>0.603755</td>\n",
       "      <td>0.603755</td>\n",
       "      <td>0.603755</td>\n",
       "      <td>0.603755</td>\n",
       "      <td>0.603755</td>\n",
       "      <td>12.65</td>\n",
       "      <td>-8.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.735562</td>\n",
       "      <td>-0.684055</td>\n",
       "      <td>2.058215</td>\n",
       "      <td>0.716328</td>\n",
       "      <td>-0.011393</td>\n",
       "      <td>0.805396</td>\n",
       "      <td>1.497982</td>\n",
       "      <td>0.114752</td>\n",
       "      <td>0.692847</td>\n",
       "      <td>0.052377</td>\n",
       "      <td>...</td>\n",
       "      <td>0.187169</td>\n",
       "      <td>0.187169</td>\n",
       "      <td>0.187169</td>\n",
       "      <td>0.187169</td>\n",
       "      <td>0.187169</td>\n",
       "      <td>0.187169</td>\n",
       "      <td>0.187169</td>\n",
       "      <td>0.187169</td>\n",
       "      <td>9.03</td>\n",
       "      <td>38.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.570272</td>\n",
       "      <td>0.273157</td>\n",
       "      <td>-0.279214</td>\n",
       "      <td>0.083456</td>\n",
       "      <td>1.049331</td>\n",
       "      <td>-0.869295</td>\n",
       "      <td>-0.265858</td>\n",
       "      <td>-0.401676</td>\n",
       "      <td>-0.872639</td>\n",
       "      <td>1.147483</td>\n",
       "      <td>...</td>\n",
       "      <td>1.620715</td>\n",
       "      <td>1.620715</td>\n",
       "      <td>1.620715</td>\n",
       "      <td>1.620715</td>\n",
       "      <td>1.620715</td>\n",
       "      <td>1.620715</td>\n",
       "      <td>1.620715</td>\n",
       "      <td>1.620715</td>\n",
       "      <td>34.03</td>\n",
       "      <td>-6.85</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 118 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6    \\\n",
       "0  7.161286  7.835325  2.911583  0.984049 -1.499546 -2.094097  0.576000   \n",
       "1  0.225763 -0.094169 -0.603646  0.497745  0.874036  0.290280 -0.077659   \n",
       "2 -0.692525 -0.517801 -0.788035  1.214351 -0.907214  0.880213  0.406899   \n",
       "3 -0.735562 -0.684055  2.058215  0.716328 -0.011393  0.805396  1.497982   \n",
       "4  0.570272  0.273157 -0.279214  0.083456  1.049331 -0.869295 -0.265858   \n",
       "\n",
       "        7         8         9    ...         108       109       110  \\\n",
       "0 -1.205671  1.849122 -0.425598  ...   -0.364194 -0.364194 -0.364194   \n",
       "1 -0.887385  0.432062 -0.093963  ...    0.936616  0.936616  0.936616   \n",
       "2 -0.694895 -0.901869 -1.701574  ...    0.603755  0.603755  0.603755   \n",
       "3  0.114752  0.692847  0.052377  ...    0.187169  0.187169  0.187169   \n",
       "4 -0.401676 -0.872639  1.147483  ...    1.620715  1.620715  1.620715   \n",
       "\n",
       "        111       112       113       114       115    116    117  \n",
       "0 -0.364194 -0.364194 -0.364194 -0.364194 -0.364194 -15.75 -47.95  \n",
       "1  0.936616  0.936616  0.936616  0.936616  0.936616  14.91 -23.51  \n",
       "2  0.603755  0.603755  0.603755  0.603755  0.603755  12.65  -8.00  \n",
       "3  0.187169  0.187169  0.187169  0.187169  0.187169   9.03  38.74  \n",
       "4  1.620715  1.620715  1.620715  1.620715  1.620715  34.03  -6.85  \n",
       "\n",
       "[5 rows x 118 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "music_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1059, 118)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "music_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1059.000000\n",
       "mean       26.651294\n",
       "std        18.459432\n",
       "min       -35.300000\n",
       "25%        14.660000\n",
       "50%        33.660000\n",
       "75%        39.910000\n",
       "max        54.680000\n",
       "Name: 116, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "music_df[116].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1059.000000\n",
       "mean       38.405656\n",
       "std        50.419790\n",
       "min       -88.760000\n",
       "25%         3.210000\n",
       "50%        32.830000\n",
       "75%        74.600000\n",
       "max       149.120000\n",
       "Name: 117, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "music_df[117].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-15.75</td>\n",
       "      <td>-47.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14.91</td>\n",
       "      <td>-23.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12.65</td>\n",
       "      <td>-8.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.03</td>\n",
       "      <td>38.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>34.03</td>\n",
       "      <td>-6.85</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     lat   long\n",
       "0 -15.75 -47.95\n",
       "1  14.91 -23.51\n",
       "2  12.65  -8.00\n",
       "3   9.03  38.74\n",
       "4  34.03  -6.85"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "just_coord = music_df[[116,117]].copy()\n",
    "just_coord.columns = ['lat', 'long']\n",
    "just_coord.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we create the labels for the data by dividing the globe into 16 equal parts, and assign a label/class based on which range the lat/long pair fits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "just_coord.loc[(just_coord.lat <= 90) & (just_coord.lat >= 45) & (just_coord.long >= -180) & (just_coord.long <= -90), 'label'] = 1\n",
    "just_coord.loc[(just_coord.lat <= 90) & (just_coord.lat >= 45) & (just_coord.long >= -90) & (just_coord.long <= 0), 'label'] = 2\n",
    "just_coord.loc[(just_coord.lat <= 90) & (just_coord.lat >= 45) & (just_coord.long >= 0) & (just_coord.long <= 90), 'label'] = 3\n",
    "just_coord.loc[(just_coord.lat <= 90) & (just_coord.lat >= 45) & (just_coord.long >= 90) & (just_coord.long <= 180), 'label'] = 4\n",
    "just_coord.loc[(just_coord.lat <= 45) & (just_coord.lat >= 0) & (just_coord.long >= -180) & (just_coord.long <= -90), 'label'] = 5\n",
    "just_coord.loc[(just_coord.lat <= 45) & (just_coord.lat >= 0) & (just_coord.long >= -90) & (just_coord.long <= 0), 'label'] = 6\n",
    "just_coord.loc[(just_coord.lat <= 45) & (just_coord.lat >= 0) & (just_coord.long >= 0) & (just_coord.long <= 90), 'label'] = 7\n",
    "just_coord.loc[(just_coord.lat <= 45) & (just_coord.lat >= 0) & (just_coord.long >= 90) & (just_coord.long <= 180), 'label'] = 8\n",
    "just_coord.loc[(just_coord.lat <= 0) & (just_coord.lat >= -45) & (just_coord.long >= -180) & (just_coord.long <= -90), 'label'] = 9\n",
    "just_coord.loc[(just_coord.lat <= 0) & (just_coord.lat >= -45) & (just_coord.long >= -90) & (just_coord.long <= 0), 'label'] = 10\n",
    "just_coord.loc[(just_coord.lat <= 0) & (just_coord.lat >= -45) & (just_coord.long >= 0) & (just_coord.long <= 90), 'label'] = 11\n",
    "just_coord.loc[(just_coord.lat <= 0) & (just_coord.lat >= -45) & (just_coord.long >= 90) & (just_coord.long <= 180), 'label'] = 12\n",
    "just_coord.loc[(just_coord.lat <= -45) & (just_coord.lat >= -90) & (just_coord.long >= -180) & (just_coord.long <= -90), 'label'] = 13\n",
    "just_coord.loc[(just_coord.lat <= -45) & (just_coord.lat >= -90) & (just_coord.long >= -90) & (just_coord.long <= 0), 'label'] = 14\n",
    "just_coord.loc[(just_coord.lat <= -45) & (just_coord.lat >= -90) & (just_coord.long >= 0) & (just_coord.long <= 90), 'label'] = 15\n",
    "just_coord.loc[(just_coord.lat <= -45) & (just_coord.lat >= -90) & (just_coord.long >= 90) & (just_coord.long <= 180), 'label'] = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-15.75</td>\n",
       "      <td>-47.95</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14.91</td>\n",
       "      <td>-23.51</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12.65</td>\n",
       "      <td>-8.00</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.03</td>\n",
       "      <td>38.74</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>34.03</td>\n",
       "      <td>-6.85</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>12.65</td>\n",
       "      <td>-8.00</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>12.65</td>\n",
       "      <td>-8.00</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>14.66</td>\n",
       "      <td>-17.41</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>52.50</td>\n",
       "      <td>-0.12</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>41.26</td>\n",
       "      <td>69.21</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>41.26</td>\n",
       "      <td>69.21</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>41.90</td>\n",
       "      <td>12.48</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>28.61</td>\n",
       "      <td>77.20</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>33.66</td>\n",
       "      <td>73.16</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>54.68</td>\n",
       "      <td>25.31</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>44.41</td>\n",
       "      <td>26.10</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>44.41</td>\n",
       "      <td>26.10</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>52.50</td>\n",
       "      <td>-0.12</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>44.41</td>\n",
       "      <td>26.10</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>44.41</td>\n",
       "      <td>26.10</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      lat   long  label\n",
       "0  -15.75 -47.95   10.0\n",
       "1   14.91 -23.51    6.0\n",
       "2   12.65  -8.00    6.0\n",
       "3    9.03  38.74    7.0\n",
       "4   34.03  -6.85    6.0\n",
       "5   12.65  -8.00    6.0\n",
       "6   12.65  -8.00    6.0\n",
       "7   14.66 -17.41    6.0\n",
       "8   52.50  -0.12    2.0\n",
       "9   41.26  69.21    7.0\n",
       "10  41.26  69.21    7.0\n",
       "11  41.90  12.48    7.0\n",
       "12  28.61  77.20    7.0\n",
       "13  33.66  73.16    7.0\n",
       "14  54.68  25.31    3.0\n",
       "15  44.41  26.10    7.0\n",
       "16  44.41  26.10    7.0\n",
       "17  52.50  -0.12    2.0\n",
       "18  44.41  26.10    7.0\n",
       "19  44.41  26.10    7.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "just_coord.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at how balanced our classes are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.0     527\n",
       "6.0     190\n",
       "8.0     150\n",
       "11.0     52\n",
       "12.0     39\n",
       "10.0     36\n",
       "2.0      33\n",
       "3.0      32\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "just_coord.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'Count')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "f, ax = plt.subplots(figsize=(8, 6))\n",
    "sns.countplot(just_coord.label)\n",
    "plt.title('Distribution of Geographic Classes/Labels', fontsize=15)\n",
    "plt.xlabel('Class', fontsize=12)\n",
    "plt.ylabel('Count', fontsize=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, we can already tell that we are going to have an issue with unbalanced classes. In addition, half of the map classes that we created don't have any datapoints in them, so our model will likely only work on music coming from locations that are represented in our data.\n",
    "\n",
    "Here is the section that is over-represented in the data.\n",
    "\n",
    "<img src=\"Section 7.png\">\n",
    "\n",
    "This region includes nearly all of Northern Africa, the Middle East, India, and many other places with a rich musical heritage. So, it would make sense that a lot of our data comes from this region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([], dtype='int64')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Double check that there is no missing data\n",
    "music_df.columns[music_df.isnull().any()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sweet! As reported in the [data description where we got the data](http://archive.ics.uci.edu/ml/datasets/geographical+original+of+music), there is no missing data! So, we can proceed with scaling the data, and then getting into the modeling!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new df without lats and longs\n",
    "X_df = music_df.copy().drop([116,117], axis=1)\n",
    "\n",
    "# Train-Test-Split for later testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_df, just_coord.label, test_size=.2, random_state=42)\n",
    "\n",
    "# Scale the data (fit the Standard Scaler on the training set, then fit both the training and test sets to it)\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = pd.DataFrame(scaler.transform(X_train))\n",
    "X_test = pd.DataFrame(scaler.transform(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TTSplit for validation\n",
    "x_tr, x_val, y_tr, y_val = train_test_split(X_train, y_train, test_size = .2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>106</th>\n",
       "      <th>107</th>\n",
       "      <th>108</th>\n",
       "      <th>109</th>\n",
       "      <th>110</th>\n",
       "      <th>111</th>\n",
       "      <th>112</th>\n",
       "      <th>113</th>\n",
       "      <th>114</th>\n",
       "      <th>115</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>-0.738151</td>\n",
       "      <td>-0.466010</td>\n",
       "      <td>-0.799208</td>\n",
       "      <td>-0.523743</td>\n",
       "      <td>-3.285186</td>\n",
       "      <td>1.852218</td>\n",
       "      <td>1.853192</td>\n",
       "      <td>-0.341898</td>\n",
       "      <td>0.656776</td>\n",
       "      <td>0.282785</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.756365</td>\n",
       "      <td>-0.756365</td>\n",
       "      <td>-0.756365</td>\n",
       "      <td>-0.756365</td>\n",
       "      <td>-0.756365</td>\n",
       "      <td>-0.756365</td>\n",
       "      <td>-0.756365</td>\n",
       "      <td>-0.756365</td>\n",
       "      <td>-0.756365</td>\n",
       "      <td>-0.756365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>828</th>\n",
       "      <td>-0.303556</td>\n",
       "      <td>-0.608302</td>\n",
       "      <td>0.417542</td>\n",
       "      <td>0.552270</td>\n",
       "      <td>0.741851</td>\n",
       "      <td>-0.637480</td>\n",
       "      <td>-0.614212</td>\n",
       "      <td>-0.595187</td>\n",
       "      <td>-0.479784</td>\n",
       "      <td>1.168692</td>\n",
       "      <td>...</td>\n",
       "      <td>1.814921</td>\n",
       "      <td>1.814921</td>\n",
       "      <td>1.814921</td>\n",
       "      <td>1.814921</td>\n",
       "      <td>1.814921</td>\n",
       "      <td>1.814921</td>\n",
       "      <td>1.814921</td>\n",
       "      <td>1.814921</td>\n",
       "      <td>1.814921</td>\n",
       "      <td>1.814921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.193634</td>\n",
       "      <td>-0.090246</td>\n",
       "      <td>-0.687070</td>\n",
       "      <td>1.165341</td>\n",
       "      <td>0.250938</td>\n",
       "      <td>1.924881</td>\n",
       "      <td>-2.087244</td>\n",
       "      <td>-0.687825</td>\n",
       "      <td>-1.508443</td>\n",
       "      <td>-0.716167</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.487445</td>\n",
       "      <td>-0.487445</td>\n",
       "      <td>-0.487445</td>\n",
       "      <td>-0.487445</td>\n",
       "      <td>-0.487445</td>\n",
       "      <td>-0.487445</td>\n",
       "      <td>-0.487445</td>\n",
       "      <td>-0.487445</td>\n",
       "      <td>-0.487445</td>\n",
       "      <td>-0.487445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>-0.340446</td>\n",
       "      <td>-0.752372</td>\n",
       "      <td>-0.793308</td>\n",
       "      <td>-0.449808</td>\n",
       "      <td>0.107686</td>\n",
       "      <td>0.254948</td>\n",
       "      <td>1.526699</td>\n",
       "      <td>-0.540545</td>\n",
       "      <td>-1.066032</td>\n",
       "      <td>0.900452</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.127507</td>\n",
       "      <td>-0.127507</td>\n",
       "      <td>-0.127507</td>\n",
       "      <td>-0.127507</td>\n",
       "      <td>-0.127507</td>\n",
       "      <td>-0.127507</td>\n",
       "      <td>-0.127507</td>\n",
       "      <td>-0.127507</td>\n",
       "      <td>-0.127507</td>\n",
       "      <td>-0.127507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>660</th>\n",
       "      <td>0.597994</td>\n",
       "      <td>0.977786</td>\n",
       "      <td>0.004083</td>\n",
       "      <td>0.002835</td>\n",
       "      <td>0.507437</td>\n",
       "      <td>-1.575479</td>\n",
       "      <td>0.557926</td>\n",
       "      <td>2.839942</td>\n",
       "      <td>-0.578979</td>\n",
       "      <td>-0.100907</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.313682</td>\n",
       "      <td>-0.313682</td>\n",
       "      <td>-0.313682</td>\n",
       "      <td>-0.313682</td>\n",
       "      <td>-0.313682</td>\n",
       "      <td>-0.313682</td>\n",
       "      <td>-0.313682</td>\n",
       "      <td>-0.313682</td>\n",
       "      <td>-0.313682</td>\n",
       "      <td>-0.313682</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 116 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6    \\\n",
       "338 -0.738151 -0.466010 -0.799208 -0.523743 -3.285186  1.852218  1.853192   \n",
       "828 -0.303556 -0.608302  0.417542  0.552270  0.741851 -0.637480 -0.614212   \n",
       "2   -0.193634 -0.090246 -0.687070  1.165341  0.250938  1.924881 -2.087244   \n",
       "296 -0.340446 -0.752372 -0.793308 -0.449808  0.107686  0.254948  1.526699   \n",
       "660  0.597994  0.977786  0.004083  0.002835  0.507437 -1.575479  0.557926   \n",
       "\n",
       "          7         8         9      ...          106       107       108  \\\n",
       "338 -0.341898  0.656776  0.282785    ...    -0.756365 -0.756365 -0.756365   \n",
       "828 -0.595187 -0.479784  1.168692    ...     1.814921  1.814921  1.814921   \n",
       "2   -0.687825 -1.508443 -0.716167    ...    -0.487445 -0.487445 -0.487445   \n",
       "296 -0.540545 -1.066032  0.900452    ...    -0.127507 -0.127507 -0.127507   \n",
       "660  2.839942 -0.578979 -0.100907    ...    -0.313682 -0.313682 -0.313682   \n",
       "\n",
       "          109       110       111       112       113       114       115  \n",
       "338 -0.756365 -0.756365 -0.756365 -0.756365 -0.756365 -0.756365 -0.756365  \n",
       "828  1.814921  1.814921  1.814921  1.814921  1.814921  1.814921  1.814921  \n",
       "2   -0.487445 -0.487445 -0.487445 -0.487445 -0.487445 -0.487445 -0.487445  \n",
       "296 -0.127507 -0.127507 -0.127507 -0.127507 -0.127507 -0.127507 -0.127507  \n",
       "660 -0.313682 -0.313682 -0.313682 -0.313682 -0.313682 -0.313682 -0.313682  \n",
       "\n",
       "[5 rows x 116 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_tr.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's run some classifiers, just to see how they compare right out of the gate. Note that we will first test them on all the training data we have before moving on to tuning the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_clf(clf):\n",
    "    score = cross_val_score(clf, X_train, y_train, scoring = 'f1_macro', cv = 10)\n",
    "    print(clf.__class__.__name__,\"Score =\", score.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression Score = 0.4652046110669992\n",
      "KNeighborsClassifier Score = 0.4681695069563535\n",
      "SVC Score = 0.3777264390700916\n",
      "DecisionTreeClassifier Score = 0.3503635103529291\n",
      "RandomForestClassifier Score = 0.367014036698922\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "knn = KNeighborsClassifier()\n",
    "svc = SVC()\n",
    "dt = DecisionTreeClassifier()\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "models = [lr, knn, svc, dt, rf]\n",
    "for clf in models:\n",
    "    test_clf(clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow, KNN did surprisingly well, as did Logistic Regression. I'm going to move forward with tuning on KNN and Random Forest, which scored third best, but I think has the best potential for improvement moving forward. Let's mess around with KNN first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 12 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    4.1s\n",
      "[Parallel(n_jobs=-1)]: Done 120 out of 120 | elapsed:    7.3s finished\n",
      "C:\\Users\\reide\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise-deprecating',\n",
       "       estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=-1, n_neighbors=5, p=2,\n",
       "           weights='uniform'),\n",
       "       fit_params=None, iid='warn', n_jobs=-1,\n",
       "       param_grid={'n_neighbors': [3, 5, 10], 'leaf_size': [10, 20, 30, 50]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='f1_macro', verbose=2)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_dictionary = {\"n_neighbors\": [3, 5, 10], 'leaf_size':[10,20,30,50]}\n",
    "clf = KNeighborsClassifier(n_jobs=-1)\n",
    "gs = GridSearchCV(clf, param_dictionary, scoring='f1_macro', n_jobs=-1, verbose=2, cv=10)\n",
    "gs.fit(x_tr, y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'leaf_size': 10, 'n_neighbors': 3}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Scores:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         2.0       0.81      0.71      0.76        24\n",
      "         3.0       0.95      1.00      0.97        19\n",
      "         6.0       0.65      0.82      0.72       127\n",
      "         7.0       0.78      0.89      0.83       322\n",
      "         8.0       0.88      0.59      0.70        99\n",
      "        10.0       0.86      0.23      0.36        26\n",
      "        11.0       0.83      0.58      0.68        33\n",
      "        12.0       0.82      0.33      0.47        27\n",
      "\n",
      "   micro avg       0.77      0.77      0.77       677\n",
      "   macro avg       0.82      0.64      0.69       677\n",
      "weighted avg       0.78      0.77      0.76       677\n",
      "\n",
      "--------------------------------------------------\n",
      "F1 Score: 0.6883937551630348\n"
     ]
    }
   ],
   "source": [
    "train_predictions = gs.predict(x_tr)\n",
    "cr = classification_report(y_tr, train_predictions)\n",
    "f1_trained_score = f1_score(y_tr, train_predictions, average = 'macro')\n",
    "print(\"Training Scores:\")\n",
    "print(cr)\n",
    "print(\"-\"*50)\n",
    "print(f\"F1 Score: {f1_trained_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Scores:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         2.0       0.29      0.67      0.40         3\n",
      "         3.0       0.60      0.50      0.55         6\n",
      "         6.0       0.50      0.69      0.58        32\n",
      "         7.0       0.69      0.79      0.74        81\n",
      "         8.0       0.81      0.45      0.58        29\n",
      "        10.0       0.00      0.00      0.00         4\n",
      "        11.0       0.40      0.18      0.25        11\n",
      "        12.0       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.62      0.62      0.62       170\n",
      "   macro avg       0.41      0.41      0.39       170\n",
      "weighted avg       0.61      0.62      0.60       170\n",
      "\n",
      "--------------------------------------------------\n",
      "F1 Score: 0.38597648444517774\n"
     ]
    }
   ],
   "source": [
    "val_predictions = gs.predict(x_val)\n",
    "cr = classification_report(y_val, val_predictions)\n",
    "f1_trained_score = f1_score(y_val, val_predictions, average = 'macro')\n",
    "print(\"Validation Scores:\")\n",
    "print(cr)\n",
    "print(\"-\"*50)\n",
    "print(f\"F1 Score: {f1_trained_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, we tried out some different values for the hyperparameters for KNN, and used the \"best\" ones to fit a model. The F1 in the training data is a \"meh\" 0.688, but once we predict on the validation set, we can see that there is quite a bit of overfitting going on, with the F1 dropping down to 0.38, which is worse than it performed on the original set.\n",
    "\n",
    "We have a few options here. We could continue tweaking with the hyperparameters to perhaps get a lower F1 in training, but reduce the overfitting issue. Or, we could switch to another model that is less prone to overfitting, like the Random Forest. Because Random Forest tends to do rather well, has a lot of upside potential, and also is not so easy to overfit, we're going to take the latter option, switch to Random Forest, and then continue to tweak from there. (Note that it helps that the researchers who originally created this dataset ended up using Random Forest, and it performed the best for them, so...if it ain't broke...)\n",
    "\n",
    "Another benefit of the Random Forest Classifier is that one of sklearn's options for the built-in implementation is a \"class weight\" category. This is useful because, as we showed above, we are definitely dealing with a case of unbalanced classes. Once we get to tweaking the model, hopefully we'll be able to not only improve on the overfitting we saw before, but get up to a higher F1 than we have seen previously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 15 candidates, totalling 150 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    2.5s\n",
      "[Parallel(n_jobs=-1)]: Done 150 out of 150 | elapsed:   50.2s finished\n",
      "C:\\Users\\reide\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise-deprecating',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
       "            criterion='gini', max_depth=None, max_features='auto',\n",
       "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "            min_impurity_split=None, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators='warn', n_jobs=-1, oob_score=False,\n",
       "            random_state=42, verbose=0, warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=-1,\n",
       "       param_grid={'n_estimators': [100, 500, 1000], 'max_depth': [1, 2, 3, 5, 10]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='f1_macro', verbose=2)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_dictionary = {\"n_estimators\": [100, 500, 1000], \"max_depth\": [1,2,3,5,10]}\n",
    "clf = RandomForestClassifier(n_jobs=-1, class_weight='balanced', random_state=42)\n",
    "gs = GridSearchCV(clf, param_dictionary, scoring='f1_macro', n_jobs=-1, verbose=2, cv=10)\n",
    "gs.fit(x_tr, y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 5, 'n_estimators': 500}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Scores:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         2.0       1.00      0.92      0.96        24\n",
      "         3.0       0.95      0.95      0.95        19\n",
      "         6.0       0.73      0.50      0.59       127\n",
      "         7.0       0.87      0.58      0.70       322\n",
      "         8.0       0.58      0.86      0.69        99\n",
      "        10.0       0.52      0.88      0.66        26\n",
      "        11.0       0.45      0.97      0.62        33\n",
      "        12.0       0.34      0.93      0.50        27\n",
      "\n",
      "   micro avg       0.67      0.67      0.67       677\n",
      "   macro avg       0.68      0.82      0.71       677\n",
      "weighted avg       0.76      0.67      0.68       677\n",
      "\n",
      "--------------------------------------------------\n",
      "F1 Score: 0.7071350255244228\n"
     ]
    }
   ],
   "source": [
    "train_predictions = gs.predict(x_tr)\n",
    "cr = classification_report(y_tr, train_predictions)\n",
    "f1_trained_score = f1_score(y_tr, train_predictions, average = 'macro')\n",
    "print(\"Training Scores:\")\n",
    "print(cr)\n",
    "print(\"-\"*50)\n",
    "print(f\"F1 Score: {f1_trained_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice! We're already to a higher F1 than we have seen previously. However, let's check to see how bad we might be overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Scores:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         2.0       1.00      0.67      0.80         3\n",
      "         3.0       0.43      0.50      0.46         6\n",
      "         6.0       0.44      0.38      0.41        32\n",
      "         7.0       0.71      0.46      0.56        81\n",
      "         8.0       0.47      0.69      0.56        29\n",
      "        10.0       0.10      0.25      0.14         4\n",
      "        11.0       0.06      0.09      0.07        11\n",
      "        12.0       0.15      0.50      0.24         4\n",
      "\n",
      "   micro avg       0.46      0.46      0.46       170\n",
      "   macro avg       0.42      0.44      0.40       170\n",
      "weighted avg       0.54      0.46      0.48       170\n",
      "\n",
      "--------------------------------------------------\n",
      "F1 Score: 0.4040612487666064\n"
     ]
    }
   ],
   "source": [
    "val_predictions = gs.predict(x_val)\n",
    "cr = classification_report(y_val, val_predictions)\n",
    "f1_trained_score = f1_score(y_val, val_predictions, average = 'macro')\n",
    "print(\"Validation Scores:\")\n",
    "print(cr)\n",
    "print(\"-\"*50)\n",
    "print(f\"F1 Score: {f1_trained_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yikes. As expected, we are definitely in the realm of overfitting. One thing we can do is manually lower the max_depth hyperparameter, which will bring down our F1, but should help with the overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:    2.5s remaining:    2.5s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    2.8s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise-deprecating',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
       "            criterion='gini', max_depth=None, max_features='auto',\n",
       "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "            min_impurity_split=None, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=500, n_jobs=-1, oob_score=False, random_state=42,\n",
       "            verbose=0, warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=-1,\n",
       "       param_grid={'max_depth': [3]}, pre_dispatch='2*n_jobs', refit=True,\n",
       "       return_train_score='warn', scoring='f1_macro', verbose=2)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_dictionary = {\"max_depth\": [3]}\n",
    "clf = RandomForestClassifier(n_jobs=-1, class_weight='balanced', random_state=42, n_estimators=500)\n",
    "gs = GridSearchCV(clf, param_dictionary, scoring='f1_macro', n_jobs=-1, verbose=2, cv=10)\n",
    "gs.fit(x_tr, y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Scores:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         2.0       0.76      0.67      0.71        24\n",
      "         3.0       0.55      0.89      0.68        19\n",
      "         6.0       0.55      0.23      0.32       127\n",
      "         7.0       0.82      0.22      0.35       322\n",
      "         8.0       0.47      0.66      0.55        99\n",
      "        10.0       0.22      0.77      0.35        26\n",
      "        11.0       0.22      0.91      0.36        33\n",
      "        12.0       0.17      0.78      0.28        27\n",
      "\n",
      "   micro avg       0.40      0.40      0.40       677\n",
      "   macro avg       0.47      0.64      0.45       677\n",
      "weighted avg       0.63      0.40      0.39       677\n",
      "\n",
      "--------------------------------------------------\n",
      "F1 Score: 0.44931046181034356\n"
     ]
    }
   ],
   "source": [
    "train_predictions = gs.predict(x_tr)\n",
    "cr = classification_report(y_tr, train_predictions)\n",
    "f1_trained_score = f1_score(y_tr, train_predictions, average = 'macro')\n",
    "print(\"Training Scores:\")\n",
    "print(cr)\n",
    "print(\"-\"*50)\n",
    "print(f\"F1 Score: {f1_trained_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Scores:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         2.0       1.00      0.67      0.80         3\n",
      "         3.0       0.33      0.50      0.40         6\n",
      "         6.0       0.47      0.22      0.30        32\n",
      "         7.0       0.81      0.31      0.45        81\n",
      "         8.0       0.42      0.55      0.48        29\n",
      "        10.0       0.11      0.50      0.17         4\n",
      "        11.0       0.10      0.27      0.14        11\n",
      "        12.0       0.08      0.50      0.14         4\n",
      "\n",
      "   micro avg       0.35      0.35      0.35       170\n",
      "   macro avg       0.41      0.44      0.36       170\n",
      "weighted avg       0.58      0.35      0.40       170\n",
      "\n",
      "--------------------------------------------------\n",
      "F1 Score: 0.3595767591213467\n"
     ]
    }
   ],
   "source": [
    "val_predictions = gs.predict(x_val)\n",
    "cr = classification_report(y_val, val_predictions)\n",
    "f1_trained_score = f1_score(y_val, val_predictions, average = 'macro')\n",
    "print(\"Validation Scores:\")\n",
    "print(cr)\n",
    "print(\"-\"*50)\n",
    "print(f\"F1 Score: {f1_trained_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, on the plus side, the overfitting problem is a lot lower than it was before, but our F1 still took a massive hit. In addition, even though the variance between the sets is lower than it was, the validation F1 in the model that was overfitting still outperformed the validation F1 in this one.\n",
    "\n",
    "So, what are our options? One of the \"go-to\" options for overfitting is to reduce the number of features in the model. A great way of doing this without losing a lot of the variation across the features is to use Principle Component Analysis (PCA)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For now, we are going to stick with the model that has a greater level of overfitting, but performs better on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:    3.1s remaining:    3.1s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    3.5s finished\n",
      "C:\\Users\\reide\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise-deprecating',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
       "            criterion='gini', max_depth=None, max_features='auto',\n",
       "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "            min_impurity_split=None, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators='warn', n_jobs=-1, oob_score=False,\n",
       "            random_state=42, verbose=0, warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=-1,\n",
       "       param_grid={'max_depth': [5], 'n_estimators': [500]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='f1_macro', verbose=2)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_dictionary = {\"max_depth\": [5], 'n_estimators': [500]}\n",
    "clf = RandomForestClassifier(n_jobs=-1, class_weight='balanced', random_state=42)\n",
    "gs = GridSearchCV(clf, param_dictionary, scoring='f1_macro', n_jobs=-1, verbose=2, cv=10)\n",
    "gs.fit(x_tr, y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Scores:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         2.0       1.00      0.89      0.94        27\n",
      "         3.0       0.81      0.84      0.82        25\n",
      "         6.0       0.66      0.47      0.55       159\n",
      "         7.0       0.84      0.56      0.67       403\n",
      "         8.0       0.56      0.82      0.66       128\n",
      "        10.0       0.44      0.80      0.57        30\n",
      "        11.0       0.38      0.75      0.50        44\n",
      "        12.0       0.31      0.87      0.46        31\n",
      "\n",
      "   micro avg       0.63      0.63      0.63       847\n",
      "   macro avg       0.63      0.75      0.65       847\n",
      "weighted avg       0.71      0.63      0.64       847\n",
      "\n",
      "--------------------------------------------------\n",
      "F1 Score: 0.6478939141777655\n"
     ]
    }
   ],
   "source": [
    "train_predictions = gs.predict(X_train)\n",
    "cr = classification_report(y_train, train_predictions)\n",
    "f1_trained_score = f1_score(y_train, train_predictions, average = 'macro')\n",
    "print(\"Training Scores:\")\n",
    "print(cr)\n",
    "print(\"-\"*50)\n",
    "print(f\"F1 Score: {f1_trained_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Scores:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         2.0       1.00      0.67      0.80         6\n",
      "         3.0       0.62      0.71      0.67         7\n",
      "         6.0       0.37      0.32      0.34        31\n",
      "         7.0       0.74      0.45      0.56       124\n",
      "         8.0       0.33      0.59      0.42        22\n",
      "        10.0       0.06      0.17      0.08         6\n",
      "        11.0       0.25      0.62      0.36         8\n",
      "        12.0       0.11      0.25      0.15         8\n",
      "\n",
      "   micro avg       0.45      0.45      0.45       212\n",
      "   macro avg       0.43      0.47      0.42       212\n",
      "weighted avg       0.58      0.45      0.49       212\n",
      "\n",
      "--------------------------------------------------\n",
      "F1 Score: 0.4224341787759474\n"
     ]
    }
   ],
   "source": [
    "val_predictions = gs.predict(X_test)\n",
    "cr = classification_report(y_test, val_predictions)\n",
    "f1_trained_score = f1_score(y_test, val_predictions, average = 'macro')\n",
    "print(\"Validation Scores:\")\n",
    "print(cr)\n",
    "print(\"-\"*50)\n",
    "print(f\"F1 Score: {f1_trained_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_learning_curve(estimator, title, X, y, ylim=None, cv=None,\n",
    "                        n_jobs=None, train_sizes=np.linspace(.1, 1.0, 5)):\n",
    "    \"\"\"\n",
    "    Generate a simple plot of the test and training learning curve.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    estimator : object type that implements the \"fit\" and \"predict\" methods\n",
    "        An object of that type which is cloned for each validation.\n",
    "\n",
    "    title : string\n",
    "        Title for the chart.\n",
    "\n",
    "    X : array-like, shape (n_samples, n_features)\n",
    "        Training vector, where n_samples is the number of samples and\n",
    "        n_features is the number of features.\n",
    "\n",
    "    y : array-like, shape (n_samples) or (n_samples, n_features), optional\n",
    "        Target relative to X for classification or regression;\n",
    "        None for unsupervised learning.\n",
    "\n",
    "    ylim : tuple, shape (ymin, ymax), optional\n",
    "        Defines minimum and maximum yvalues plotted.\n",
    "\n",
    "    cv : int, cross-validation generator or an iterable, optional\n",
    "        Determines the cross-validation splitting strategy.\n",
    "        Possible inputs for cv are:\n",
    "          - None, to use the default 3-fold cross-validation,\n",
    "          - integer, to specify the number of folds.\n",
    "          - :term:`CV splitter`,\n",
    "          - An iterable yielding (train, test) splits as arrays of indices.\n",
    "\n",
    "        For integer/None inputs, if ``y`` is binary or multiclass,\n",
    "        :class:`StratifiedKFold` used. If the estimator is not a classifier\n",
    "        or if ``y`` is neither binary nor multiclass, :class:`KFold` is used.\n",
    "\n",
    "        Refer :ref:`User Guide <cross_validation>` for the various\n",
    "        cross-validators that can be used here.\n",
    "\n",
    "    n_jobs : int or None, optional (default=None)\n",
    "        Number of jobs to run in parallel.\n",
    "        ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n",
    "        ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n",
    "        for more details.\n",
    "\n",
    "    train_sizes : array-like, shape (n_ticks,), dtype float or int\n",
    "        Relative or absolute numbers of training examples that will be used to\n",
    "        generate the learning curve. If the dtype is float, it is regarded as a\n",
    "        fraction of the maximum size of the training set (that is determined\n",
    "        by the selected validation method), i.e. it has to be within (0, 1].\n",
    "        Otherwise it is interpreted as absolute sizes of the training sets.\n",
    "        Note that for classification the number of samples usually have to\n",
    "        be big enough to contain at least one sample from each class.\n",
    "        (default: np.linspace(0.1, 1.0, 5))\n",
    "    \"\"\"\n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    if ylim is not None:\n",
    "        plt.ylim(*ylim)\n",
    "    plt.xlabel(\"Training examples\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    train_sizes, train_scores, test_scores = learning_curve(\n",
    "        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    plt.grid()\n",
    "\n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                     color=\"r\")\n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
    "             label=\"Training score\")\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
    "             label=\"Cross-validation score\")\n",
    "\n",
    "    plt.legend(loc=\"best\")\n",
    "    return plt\n",
    "\n",
    "title = \"Learning Curve (Random Forest)\"\n",
    "# Cross validation with 100 iterations to get smoother mean test and train\n",
    "# score curves, each time with 20% data randomly selected as a validation set.\n",
    "cv = ShuffleSplit(n_splits=10, test_size=0.2, random_state=0)\n",
    "\n",
    "estimator = RandomForestClassifier(max_depth=3, n_estimators=500)\n",
    "plot_learning_curve(estimator, title, x_tr, y_tr, ylim=(0.3, 1.01), cv=cv, n_jobs=4)\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
