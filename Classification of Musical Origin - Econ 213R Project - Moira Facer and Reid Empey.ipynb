{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Visualization libraries\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "matplotlib.style.use('fivethirtyeight')\n",
    "five_thirty_eight = [\"#30a2da\",\"#fc4f30\",\"#e5ae38\",\"#6d904f\",\"#8b8b8b\",]\n",
    "sns.set_palette(five_thirty_eight)\n",
    "%matplotlib inline\n",
    "\n",
    "# Silence deprecation warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Modeling, validation, and other SKLearn modules\n",
    "from sklearn.preprocessing import Imputer, StandardScaler\n",
    "from sklearn.model_selection import train_test_split, learning_curve, GridSearchCV, RandomizedSearchCV, cross_val_score\n",
    "from sklearn.metrics import f1_score, roc_curve, classification_report, confusion_matrix, make_scorer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\reide\\Jupyter Notebooks\\Project\\Geographical Original of Music\\default_plus_chromatic_features_1059_tracks.txt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'C:/Users/reide/Jupyter Notebooks/Project/Geographical Original of Music/default_plus_chromatic_features_1059_tracks.txt'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = r'C:\\Users\\reide\\Jupyter Notebooks\\Project\\Geographical Original of Music\\default_plus_chromatic_features_1059_tracks.txt'\n",
    "print(file_path)\n",
    "file_path.replace('\\\\', '/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "music_df = pd.read_csv('C:/Users/reide/Jupyter Notebooks/Project/Geographical Original of Music/default_plus_chromatic_features_1059_tracks.txt', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>108</th>\n",
       "      <th>109</th>\n",
       "      <th>110</th>\n",
       "      <th>111</th>\n",
       "      <th>112</th>\n",
       "      <th>113</th>\n",
       "      <th>114</th>\n",
       "      <th>115</th>\n",
       "      <th>116</th>\n",
       "      <th>117</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.161286</td>\n",
       "      <td>7.835325</td>\n",
       "      <td>2.911583</td>\n",
       "      <td>0.984049</td>\n",
       "      <td>-1.499546</td>\n",
       "      <td>-2.094097</td>\n",
       "      <td>0.576000</td>\n",
       "      <td>-1.205671</td>\n",
       "      <td>1.849122</td>\n",
       "      <td>-0.425598</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.364194</td>\n",
       "      <td>-0.364194</td>\n",
       "      <td>-0.364194</td>\n",
       "      <td>-0.364194</td>\n",
       "      <td>-0.364194</td>\n",
       "      <td>-0.364194</td>\n",
       "      <td>-0.364194</td>\n",
       "      <td>-0.364194</td>\n",
       "      <td>-15.75</td>\n",
       "      <td>-47.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.225763</td>\n",
       "      <td>-0.094169</td>\n",
       "      <td>-0.603646</td>\n",
       "      <td>0.497745</td>\n",
       "      <td>0.874036</td>\n",
       "      <td>0.290280</td>\n",
       "      <td>-0.077659</td>\n",
       "      <td>-0.887385</td>\n",
       "      <td>0.432062</td>\n",
       "      <td>-0.093963</td>\n",
       "      <td>...</td>\n",
       "      <td>0.936616</td>\n",
       "      <td>0.936616</td>\n",
       "      <td>0.936616</td>\n",
       "      <td>0.936616</td>\n",
       "      <td>0.936616</td>\n",
       "      <td>0.936616</td>\n",
       "      <td>0.936616</td>\n",
       "      <td>0.936616</td>\n",
       "      <td>14.91</td>\n",
       "      <td>-23.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.692525</td>\n",
       "      <td>-0.517801</td>\n",
       "      <td>-0.788035</td>\n",
       "      <td>1.214351</td>\n",
       "      <td>-0.907214</td>\n",
       "      <td>0.880213</td>\n",
       "      <td>0.406899</td>\n",
       "      <td>-0.694895</td>\n",
       "      <td>-0.901869</td>\n",
       "      <td>-1.701574</td>\n",
       "      <td>...</td>\n",
       "      <td>0.603755</td>\n",
       "      <td>0.603755</td>\n",
       "      <td>0.603755</td>\n",
       "      <td>0.603755</td>\n",
       "      <td>0.603755</td>\n",
       "      <td>0.603755</td>\n",
       "      <td>0.603755</td>\n",
       "      <td>0.603755</td>\n",
       "      <td>12.65</td>\n",
       "      <td>-8.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.735562</td>\n",
       "      <td>-0.684055</td>\n",
       "      <td>2.058215</td>\n",
       "      <td>0.716328</td>\n",
       "      <td>-0.011393</td>\n",
       "      <td>0.805396</td>\n",
       "      <td>1.497982</td>\n",
       "      <td>0.114752</td>\n",
       "      <td>0.692847</td>\n",
       "      <td>0.052377</td>\n",
       "      <td>...</td>\n",
       "      <td>0.187169</td>\n",
       "      <td>0.187169</td>\n",
       "      <td>0.187169</td>\n",
       "      <td>0.187169</td>\n",
       "      <td>0.187169</td>\n",
       "      <td>0.187169</td>\n",
       "      <td>0.187169</td>\n",
       "      <td>0.187169</td>\n",
       "      <td>9.03</td>\n",
       "      <td>38.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.570272</td>\n",
       "      <td>0.273157</td>\n",
       "      <td>-0.279214</td>\n",
       "      <td>0.083456</td>\n",
       "      <td>1.049331</td>\n",
       "      <td>-0.869295</td>\n",
       "      <td>-0.265858</td>\n",
       "      <td>-0.401676</td>\n",
       "      <td>-0.872639</td>\n",
       "      <td>1.147483</td>\n",
       "      <td>...</td>\n",
       "      <td>1.620715</td>\n",
       "      <td>1.620715</td>\n",
       "      <td>1.620715</td>\n",
       "      <td>1.620715</td>\n",
       "      <td>1.620715</td>\n",
       "      <td>1.620715</td>\n",
       "      <td>1.620715</td>\n",
       "      <td>1.620715</td>\n",
       "      <td>34.03</td>\n",
       "      <td>-6.85</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 118 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6    \\\n",
       "0  7.161286  7.835325  2.911583  0.984049 -1.499546 -2.094097  0.576000   \n",
       "1  0.225763 -0.094169 -0.603646  0.497745  0.874036  0.290280 -0.077659   \n",
       "2 -0.692525 -0.517801 -0.788035  1.214351 -0.907214  0.880213  0.406899   \n",
       "3 -0.735562 -0.684055  2.058215  0.716328 -0.011393  0.805396  1.497982   \n",
       "4  0.570272  0.273157 -0.279214  0.083456  1.049331 -0.869295 -0.265858   \n",
       "\n",
       "        7         8         9    ...         108       109       110  \\\n",
       "0 -1.205671  1.849122 -0.425598  ...   -0.364194 -0.364194 -0.364194   \n",
       "1 -0.887385  0.432062 -0.093963  ...    0.936616  0.936616  0.936616   \n",
       "2 -0.694895 -0.901869 -1.701574  ...    0.603755  0.603755  0.603755   \n",
       "3  0.114752  0.692847  0.052377  ...    0.187169  0.187169  0.187169   \n",
       "4 -0.401676 -0.872639  1.147483  ...    1.620715  1.620715  1.620715   \n",
       "\n",
       "        111       112       113       114       115    116    117  \n",
       "0 -0.364194 -0.364194 -0.364194 -0.364194 -0.364194 -15.75 -47.95  \n",
       "1  0.936616  0.936616  0.936616  0.936616  0.936616  14.91 -23.51  \n",
       "2  0.603755  0.603755  0.603755  0.603755  0.603755  12.65  -8.00  \n",
       "3  0.187169  0.187169  0.187169  0.187169  0.187169   9.03  38.74  \n",
       "4  1.620715  1.620715  1.620715  1.620715  1.620715  34.03  -6.85  \n",
       "\n",
       "[5 rows x 118 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "music_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1059, 118)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "music_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1059.000000\n",
       "mean       26.651294\n",
       "std        18.459432\n",
       "min       -35.300000\n",
       "25%        14.660000\n",
       "50%        33.660000\n",
       "75%        39.910000\n",
       "max        54.680000\n",
       "Name: 116, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "music_df[116].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1059.000000\n",
       "mean       38.405656\n",
       "std        50.419790\n",
       "min       -88.760000\n",
       "25%         3.210000\n",
       "50%        32.830000\n",
       "75%        74.600000\n",
       "max       149.120000\n",
       "Name: 117, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "music_df[117].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-15.75</td>\n",
       "      <td>-47.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14.91</td>\n",
       "      <td>-23.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12.65</td>\n",
       "      <td>-8.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.03</td>\n",
       "      <td>38.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>34.03</td>\n",
       "      <td>-6.85</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     lat   long\n",
       "0 -15.75 -47.95\n",
       "1  14.91 -23.51\n",
       "2  12.65  -8.00\n",
       "3   9.03  38.74\n",
       "4  34.03  -6.85"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "just_coord = music_df[[116,117]].copy()\n",
    "just_coord.columns = ['lat', 'long']\n",
    "just_coord.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we create the labels for the data by dividing the globe into 16 equal parts, and assign a label/class based on which range the lat/long pair fits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "just_coord.loc[(just_coord.lat <= 90) & (just_coord.lat >= 45) & (just_coord.long >= -180) & (just_coord.long <= -90), 'label'] = 1\n",
    "just_coord.loc[(just_coord.lat <= 90) & (just_coord.lat >= 45) & (just_coord.long >= -90) & (just_coord.long <= 0), 'label'] = 2\n",
    "just_coord.loc[(just_coord.lat <= 90) & (just_coord.lat >= 45) & (just_coord.long >= 0) & (just_coord.long <= 90), 'label'] = 3\n",
    "just_coord.loc[(just_coord.lat <= 90) & (just_coord.lat >= 45) & (just_coord.long >= 90) & (just_coord.long <= 180), 'label'] = 4\n",
    "just_coord.loc[(just_coord.lat <= 45) & (just_coord.lat >= 0) & (just_coord.long >= -180) & (just_coord.long <= -90), 'label'] = 5\n",
    "just_coord.loc[(just_coord.lat <= 45) & (just_coord.lat >= 0) & (just_coord.long >= -90) & (just_coord.long <= 0), 'label'] = 6\n",
    "just_coord.loc[(just_coord.lat <= 45) & (just_coord.lat >= 0) & (just_coord.long >= 0) & (just_coord.long <= 90), 'label'] = 7\n",
    "just_coord.loc[(just_coord.lat <= 45) & (just_coord.lat >= 0) & (just_coord.long >= 90) & (just_coord.long <= 180), 'label'] = 8\n",
    "just_coord.loc[(just_coord.lat <= 0) & (just_coord.lat >= -45) & (just_coord.long >= -180) & (just_coord.long <= -90), 'label'] = 9\n",
    "just_coord.loc[(just_coord.lat <= 0) & (just_coord.lat >= -45) & (just_coord.long >= -90) & (just_coord.long <= 0), 'label'] = 10\n",
    "just_coord.loc[(just_coord.lat <= 0) & (just_coord.lat >= -45) & (just_coord.long >= 0) & (just_coord.long <= 90), 'label'] = 11\n",
    "just_coord.loc[(just_coord.lat <= 0) & (just_coord.lat >= -45) & (just_coord.long >= 90) & (just_coord.long <= 180), 'label'] = 12\n",
    "just_coord.loc[(just_coord.lat <= -45) & (just_coord.lat >= -90) & (just_coord.long >= -180) & (just_coord.long <= -90), 'label'] = 13\n",
    "just_coord.loc[(just_coord.lat <= -45) & (just_coord.lat >= -90) & (just_coord.long >= -90) & (just_coord.long <= 0), 'label'] = 14\n",
    "just_coord.loc[(just_coord.lat <= -45) & (just_coord.lat >= -90) & (just_coord.long >= 0) & (just_coord.long <= 90), 'label'] = 15\n",
    "just_coord.loc[(just_coord.lat <= -45) & (just_coord.lat >= -90) & (just_coord.long >= 90) & (just_coord.long <= 180), 'label'] = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-15.75</td>\n",
       "      <td>-47.95</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14.91</td>\n",
       "      <td>-23.51</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12.65</td>\n",
       "      <td>-8.00</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.03</td>\n",
       "      <td>38.74</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>34.03</td>\n",
       "      <td>-6.85</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>12.65</td>\n",
       "      <td>-8.00</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>12.65</td>\n",
       "      <td>-8.00</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>14.66</td>\n",
       "      <td>-17.41</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>52.50</td>\n",
       "      <td>-0.12</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>41.26</td>\n",
       "      <td>69.21</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>41.26</td>\n",
       "      <td>69.21</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>41.90</td>\n",
       "      <td>12.48</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>28.61</td>\n",
       "      <td>77.20</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>33.66</td>\n",
       "      <td>73.16</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>54.68</td>\n",
       "      <td>25.31</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>44.41</td>\n",
       "      <td>26.10</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>44.41</td>\n",
       "      <td>26.10</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>52.50</td>\n",
       "      <td>-0.12</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>44.41</td>\n",
       "      <td>26.10</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>44.41</td>\n",
       "      <td>26.10</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      lat   long  label\n",
       "0  -15.75 -47.95   10.0\n",
       "1   14.91 -23.51    6.0\n",
       "2   12.65  -8.00    6.0\n",
       "3    9.03  38.74    7.0\n",
       "4   34.03  -6.85    6.0\n",
       "5   12.65  -8.00    6.0\n",
       "6   12.65  -8.00    6.0\n",
       "7   14.66 -17.41    6.0\n",
       "8   52.50  -0.12    2.0\n",
       "9   41.26  69.21    7.0\n",
       "10  41.26  69.21    7.0\n",
       "11  41.90  12.48    7.0\n",
       "12  28.61  77.20    7.0\n",
       "13  33.66  73.16    7.0\n",
       "14  54.68  25.31    3.0\n",
       "15  44.41  26.10    7.0\n",
       "16  44.41  26.10    7.0\n",
       "17  52.50  -0.12    2.0\n",
       "18  44.41  26.10    7.0\n",
       "19  44.41  26.10    7.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "just_coord.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at how balanced our classes are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.0     527\n",
       "6.0     190\n",
       "8.0     150\n",
       "11.0     52\n",
       "12.0     39\n",
       "10.0     36\n",
       "2.0      33\n",
       "3.0      32\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "just_coord.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'Count')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "f, ax = plt.subplots(figsize=(8, 6))\n",
    "sns.countplot(just_coord.label)\n",
    "plt.title('Distribution of Geographic Classes/Labels', fontsize=15)\n",
    "plt.xlabel('Class', fontsize=12)\n",
    "plt.ylabel('Count', fontsize=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, we can already tell that we are going to have an issue with unbalanced classes. In addition, half of the map classes that we created don't have any datapoints in them, so our model will likely only work on music coming from locations that are represented in our data.\n",
    "\n",
    "Here is the section that is over-represented in the data.\n",
    "\n",
    "<img src=\"Section 7.png\">\n",
    "\n",
    "This region includes nearly all of Northern Africa, the Middle East, India, and many other places with a rich musical heritage. So, it would make sense that a lot of our data comes from this region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([], dtype='int64')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Double check that there is no missing data\n",
    "music_df.columns[music_df.isnull().any()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sweet! As reported in the [data description where we got the data](http://archive.ics.uci.edu/ml/datasets/geographical+original+of+music), there is no missing data! So, we can proceed with scaling the data, and then getting into the modeling!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new df without lats and longs\n",
    "X_df = music_df.copy().drop([116,117], axis=1)\n",
    "\n",
    "# Train-Test-Split for later testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_df, just_coord.label, test_size=.2, random_state=42)\n",
    "\n",
    "# Scale the data (fit the Standard Scaler on the training set, then fit both the training and test sets to it)\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = pd.DataFrame(scaler.transform(X_train))\n",
    "X_test = pd.DataFrame(scaler.transform(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TTSplit for validation\n",
    "x_tr, x_val, y_tr, y_val = train_test_split(X_train, y_train, test_size = .2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>106</th>\n",
       "      <th>107</th>\n",
       "      <th>108</th>\n",
       "      <th>109</th>\n",
       "      <th>110</th>\n",
       "      <th>111</th>\n",
       "      <th>112</th>\n",
       "      <th>113</th>\n",
       "      <th>114</th>\n",
       "      <th>115</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>-0.738151</td>\n",
       "      <td>-0.466010</td>\n",
       "      <td>-0.799208</td>\n",
       "      <td>-0.523743</td>\n",
       "      <td>-3.285186</td>\n",
       "      <td>1.852218</td>\n",
       "      <td>1.853192</td>\n",
       "      <td>-0.341898</td>\n",
       "      <td>0.656776</td>\n",
       "      <td>0.282785</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.756365</td>\n",
       "      <td>-0.756365</td>\n",
       "      <td>-0.756365</td>\n",
       "      <td>-0.756365</td>\n",
       "      <td>-0.756365</td>\n",
       "      <td>-0.756365</td>\n",
       "      <td>-0.756365</td>\n",
       "      <td>-0.756365</td>\n",
       "      <td>-0.756365</td>\n",
       "      <td>-0.756365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>828</th>\n",
       "      <td>-0.303556</td>\n",
       "      <td>-0.608302</td>\n",
       "      <td>0.417542</td>\n",
       "      <td>0.552270</td>\n",
       "      <td>0.741851</td>\n",
       "      <td>-0.637480</td>\n",
       "      <td>-0.614212</td>\n",
       "      <td>-0.595187</td>\n",
       "      <td>-0.479784</td>\n",
       "      <td>1.168692</td>\n",
       "      <td>...</td>\n",
       "      <td>1.814921</td>\n",
       "      <td>1.814921</td>\n",
       "      <td>1.814921</td>\n",
       "      <td>1.814921</td>\n",
       "      <td>1.814921</td>\n",
       "      <td>1.814921</td>\n",
       "      <td>1.814921</td>\n",
       "      <td>1.814921</td>\n",
       "      <td>1.814921</td>\n",
       "      <td>1.814921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.193634</td>\n",
       "      <td>-0.090246</td>\n",
       "      <td>-0.687070</td>\n",
       "      <td>1.165341</td>\n",
       "      <td>0.250938</td>\n",
       "      <td>1.924881</td>\n",
       "      <td>-2.087244</td>\n",
       "      <td>-0.687825</td>\n",
       "      <td>-1.508443</td>\n",
       "      <td>-0.716167</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.487445</td>\n",
       "      <td>-0.487445</td>\n",
       "      <td>-0.487445</td>\n",
       "      <td>-0.487445</td>\n",
       "      <td>-0.487445</td>\n",
       "      <td>-0.487445</td>\n",
       "      <td>-0.487445</td>\n",
       "      <td>-0.487445</td>\n",
       "      <td>-0.487445</td>\n",
       "      <td>-0.487445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>-0.340446</td>\n",
       "      <td>-0.752372</td>\n",
       "      <td>-0.793308</td>\n",
       "      <td>-0.449808</td>\n",
       "      <td>0.107686</td>\n",
       "      <td>0.254948</td>\n",
       "      <td>1.526699</td>\n",
       "      <td>-0.540545</td>\n",
       "      <td>-1.066032</td>\n",
       "      <td>0.900452</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.127507</td>\n",
       "      <td>-0.127507</td>\n",
       "      <td>-0.127507</td>\n",
       "      <td>-0.127507</td>\n",
       "      <td>-0.127507</td>\n",
       "      <td>-0.127507</td>\n",
       "      <td>-0.127507</td>\n",
       "      <td>-0.127507</td>\n",
       "      <td>-0.127507</td>\n",
       "      <td>-0.127507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>660</th>\n",
       "      <td>0.597994</td>\n",
       "      <td>0.977786</td>\n",
       "      <td>0.004083</td>\n",
       "      <td>0.002835</td>\n",
       "      <td>0.507437</td>\n",
       "      <td>-1.575479</td>\n",
       "      <td>0.557926</td>\n",
       "      <td>2.839942</td>\n",
       "      <td>-0.578979</td>\n",
       "      <td>-0.100907</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.313682</td>\n",
       "      <td>-0.313682</td>\n",
       "      <td>-0.313682</td>\n",
       "      <td>-0.313682</td>\n",
       "      <td>-0.313682</td>\n",
       "      <td>-0.313682</td>\n",
       "      <td>-0.313682</td>\n",
       "      <td>-0.313682</td>\n",
       "      <td>-0.313682</td>\n",
       "      <td>-0.313682</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 116 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6    \\\n",
       "338 -0.738151 -0.466010 -0.799208 -0.523743 -3.285186  1.852218  1.853192   \n",
       "828 -0.303556 -0.608302  0.417542  0.552270  0.741851 -0.637480 -0.614212   \n",
       "2   -0.193634 -0.090246 -0.687070  1.165341  0.250938  1.924881 -2.087244   \n",
       "296 -0.340446 -0.752372 -0.793308 -0.449808  0.107686  0.254948  1.526699   \n",
       "660  0.597994  0.977786  0.004083  0.002835  0.507437 -1.575479  0.557926   \n",
       "\n",
       "          7         8         9      ...          106       107       108  \\\n",
       "338 -0.341898  0.656776  0.282785    ...    -0.756365 -0.756365 -0.756365   \n",
       "828 -0.595187 -0.479784  1.168692    ...     1.814921  1.814921  1.814921   \n",
       "2   -0.687825 -1.508443 -0.716167    ...    -0.487445 -0.487445 -0.487445   \n",
       "296 -0.540545 -1.066032  0.900452    ...    -0.127507 -0.127507 -0.127507   \n",
       "660  2.839942 -0.578979 -0.100907    ...    -0.313682 -0.313682 -0.313682   \n",
       "\n",
       "          109       110       111       112       113       114       115  \n",
       "338 -0.756365 -0.756365 -0.756365 -0.756365 -0.756365 -0.756365 -0.756365  \n",
       "828  1.814921  1.814921  1.814921  1.814921  1.814921  1.814921  1.814921  \n",
       "2   -0.487445 -0.487445 -0.487445 -0.487445 -0.487445 -0.487445 -0.487445  \n",
       "296 -0.127507 -0.127507 -0.127507 -0.127507 -0.127507 -0.127507 -0.127507  \n",
       "660 -0.313682 -0.313682 -0.313682 -0.313682 -0.313682 -0.313682 -0.313682  \n",
       "\n",
       "[5 rows x 116 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_tr.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's run some classifiers, just to see how they compare right out of the gate. Note that we will first test them on all the training data we have before moving on to tuning the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_clf(clf):\n",
    "    score = cross_val_score(clf, X_train, y_train, scoring = 'f1_macro', cv = 10)\n",
    "    print(clf.__class__.__name__,\"Score =\", score.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression Score = 0.4652046110669992\n",
      "KNeighborsClassifier Score = 0.4681695069563535\n",
      "SVC Score = 0.3777264390700916\n",
      "DecisionTreeClassifier Score = 0.35812100409124514\n",
      "RandomForestClassifier Score = 0.3932438669448075\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "knn = KNeighborsClassifier()\n",
    "svc = SVC()\n",
    "dt = DecisionTreeClassifier()\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "models = [lr, knn, svc, dt, rf]\n",
    "for clf in models:\n",
    "    test_clf(clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow, KNN did surprisingly well, as did Logistic Regression. I'm going to move forward with tuning on KNN and Random Forest, which scored third best, but I think has the best potential for improvement moving forward. Let's mess around with KNN first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 12 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    4.1s\n",
      "[Parallel(n_jobs=-1)]: Done 120 out of 120 | elapsed:    7.4s finished\n",
      "C:\\Users\\reide\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise-deprecating',\n",
       "       estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=-1, n_neighbors=5, p=2,\n",
       "           weights='uniform'),\n",
       "       fit_params=None, iid='warn', n_jobs=-1,\n",
       "       param_grid={'n_neighbors': [3, 5, 10], 'leaf_size': [10, 20, 30, 50]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='f1_macro', verbose=2)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_dictionary = {\"n_neighbors\": [3, 5, 10], 'leaf_size':[10,20,30,50]}\n",
    "clf = KNeighborsClassifier(n_jobs=-1)\n",
    "gs = GridSearchCV(clf, param_dictionary, scoring='f1_macro', n_jobs=-1, verbose=2, cv=10)\n",
    "gs.fit(x_tr, y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'leaf_size': 10, 'n_neighbors': 3}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Scores:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         2.0       0.81      0.71      0.76        24\n",
      "         3.0       0.95      1.00      0.97        19\n",
      "         6.0       0.65      0.82      0.72       127\n",
      "         7.0       0.78      0.89      0.83       322\n",
      "         8.0       0.88      0.59      0.70        99\n",
      "        10.0       0.86      0.23      0.36        26\n",
      "        11.0       0.83      0.58      0.68        33\n",
      "        12.0       0.82      0.33      0.47        27\n",
      "\n",
      "   micro avg       0.77      0.77      0.77       677\n",
      "   macro avg       0.82      0.64      0.69       677\n",
      "weighted avg       0.78      0.77      0.76       677\n",
      "\n",
      "--------------------------------------------------\n",
      "F1 Score: 0.6883937551630348\n"
     ]
    }
   ],
   "source": [
    "train_predictions = gs.predict(x_tr)\n",
    "cr = classification_report(y_tr, train_predictions)\n",
    "f1_trained_score = f1_score(y_tr, train_predictions, average = 'macro')\n",
    "print(\"Training Scores:\")\n",
    "print(cr)\n",
    "print(\"-\"*50)\n",
    "print(f\"F1 Score: {f1_trained_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Scores:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         2.0       0.29      0.67      0.40         3\n",
      "         3.0       0.60      0.50      0.55         6\n",
      "         6.0       0.50      0.69      0.58        32\n",
      "         7.0       0.69      0.79      0.74        81\n",
      "         8.0       0.81      0.45      0.58        29\n",
      "        10.0       0.00      0.00      0.00         4\n",
      "        11.0       0.40      0.18      0.25        11\n",
      "        12.0       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.62      0.62      0.62       170\n",
      "   macro avg       0.41      0.41      0.39       170\n",
      "weighted avg       0.61      0.62      0.60       170\n",
      "\n",
      "--------------------------------------------------\n",
      "F1 Score: 0.38597648444517774\n"
     ]
    }
   ],
   "source": [
    "val_predictions = gs.predict(x_val)\n",
    "cr = classification_report(y_val, val_predictions)\n",
    "f1_trained_score = f1_score(y_val, val_predictions, average = 'macro')\n",
    "print(\"Validation Scores:\")\n",
    "print(cr)\n",
    "print(\"-\"*50)\n",
    "print(f\"F1 Score: {f1_trained_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, we tried out some different values for the hyperparameters for KNN, and used the \"best\" ones to fit a model. The F1 in the training data is a \"meh\" 0.688, but once we predict on the validation set, we can see that there is quite a bit of overfitting going on, with the F1 dropping down to 0.38, which is worse than it performed on the original set.\n",
    "\n",
    "We have a few options here. We could continue tweaking with the hyperparameters to perhaps get a lower F1 in training, but reduce the overfitting issue. Or, we could switch to another model that is less prone to overfitting, like the Random Forest. Because Random Forest tends to do rather well, has a lot of upside potential, and also is not so easy to overfit, we're going to take the latter option, switch to Random Forest, and then continue to tweak from there. (Note that it helps that the researchers who originally created this dataset ended up using Random Forest, and it performed the best for them, so...if it ain't broke...)\n",
    "\n",
    "Another benefit of the Random Forest Classifier is that one of sklearn's options for the built-in implementation is a \"class weight\" category. This is useful because, as we showed above, we are definitely dealing with a case of unbalanced classes. Once we get to tweaking the model, hopefully we'll be able to not only improve on the overfitting we saw before, but get up to a higher F1 than we have seen previously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 15 candidates, totalling 150 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    2.4s\n",
      "[Parallel(n_jobs=-1)]: Done 150 out of 150 | elapsed:   48.9s finished\n",
      "C:\\Users\\reide\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise-deprecating',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
       "            criterion='gini', max_depth=None, max_features='auto',\n",
       "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "            min_impurity_split=None, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators='warn', n_jobs=-1, oob_score=False,\n",
       "            random_state=42, verbose=0, warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=-1,\n",
       "       param_grid={'n_estimators': [100, 500, 1000], 'max_depth': [1, 2, 3, 5, 10]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='f1_macro', verbose=2)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_dictionary = {\"n_estimators\": [100, 500, 1000], \"max_depth\": [1,2,3,5,10]}\n",
    "clf = RandomForestClassifier(n_jobs=-1, class_weight='balanced', random_state=42)\n",
    "gs = GridSearchCV(clf, param_dictionary, scoring='f1_macro', n_jobs=-1, verbose=2, cv=10)\n",
    "gs.fit(x_tr, y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 5, 'n_estimators': 500}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Scores:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         2.0       1.00      0.92      0.96        24\n",
      "         3.0       0.95      0.95      0.95        19\n",
      "         6.0       0.73      0.50      0.59       127\n",
      "         7.0       0.87      0.58      0.70       322\n",
      "         8.0       0.58      0.86      0.69        99\n",
      "        10.0       0.52      0.88      0.66        26\n",
      "        11.0       0.45      0.97      0.62        33\n",
      "        12.0       0.34      0.93      0.50        27\n",
      "\n",
      "   micro avg       0.67      0.67      0.67       677\n",
      "   macro avg       0.68      0.82      0.71       677\n",
      "weighted avg       0.76      0.67      0.68       677\n",
      "\n",
      "--------------------------------------------------\n",
      "F1 Score: 0.7071350255244228\n"
     ]
    }
   ],
   "source": [
    "train_predictions = gs.predict(x_tr)\n",
    "cr = classification_report(y_tr, train_predictions)\n",
    "f1_trained_score = f1_score(y_tr, train_predictions, average = 'macro')\n",
    "print(\"Training Scores:\")\n",
    "print(cr)\n",
    "print(\"-\"*50)\n",
    "print(f\"F1 Score: {f1_trained_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice! We're already to a higher F1 than we have seen previously. However, let's check to see how bad we might be overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Scores:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         2.0       1.00      0.67      0.80         3\n",
      "         3.0       0.43      0.50      0.46         6\n",
      "         6.0       0.44      0.38      0.41        32\n",
      "         7.0       0.71      0.46      0.56        81\n",
      "         8.0       0.47      0.69      0.56        29\n",
      "        10.0       0.10      0.25      0.14         4\n",
      "        11.0       0.06      0.09      0.07        11\n",
      "        12.0       0.15      0.50      0.24         4\n",
      "\n",
      "   micro avg       0.46      0.46      0.46       170\n",
      "   macro avg       0.42      0.44      0.40       170\n",
      "weighted avg       0.54      0.46      0.48       170\n",
      "\n",
      "--------------------------------------------------\n",
      "F1 Score: 0.4040612487666064\n"
     ]
    }
   ],
   "source": [
    "val_predictions = gs.predict(x_val)\n",
    "cr = classification_report(y_val, val_predictions)\n",
    "f1_trained_score = f1_score(y_val, val_predictions, average = 'macro')\n",
    "print(\"Validation Scores:\")\n",
    "print(cr)\n",
    "print(\"-\"*50)\n",
    "print(f\"F1 Score: {f1_trained_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yikes. As expected, we are definitely in the realm of overfitting. One thing we can do is manually lower the max_depth hyperparameter, which will bring down our F1, but should help with the overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:    2.4s remaining:    2.4s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    2.9s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise-deprecating',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
       "            criterion='gini', max_depth=None, max_features='auto',\n",
       "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "            min_impurity_split=None, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=500, n_jobs=-1, oob_score=False, random_state=42,\n",
       "            verbose=0, warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=-1,\n",
       "       param_grid={'max_depth': [3]}, pre_dispatch='2*n_jobs', refit=True,\n",
       "       return_train_score='warn', scoring='f1_macro', verbose=2)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_dictionary = {\"max_depth\": [3]}\n",
    "clf = RandomForestClassifier(n_jobs=-1, class_weight='balanced', random_state=42, n_estimators=500)\n",
    "gs = GridSearchCV(clf, param_dictionary, scoring='f1_macro', n_jobs=-1, verbose=2, cv=10)\n",
    "gs.fit(x_tr, y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Scores:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         2.0       0.76      0.67      0.71        24\n",
      "         3.0       0.55      0.89      0.68        19\n",
      "         6.0       0.55      0.23      0.32       127\n",
      "         7.0       0.82      0.22      0.35       322\n",
      "         8.0       0.47      0.66      0.55        99\n",
      "        10.0       0.22      0.77      0.35        26\n",
      "        11.0       0.22      0.91      0.36        33\n",
      "        12.0       0.17      0.78      0.28        27\n",
      "\n",
      "   micro avg       0.40      0.40      0.40       677\n",
      "   macro avg       0.47      0.64      0.45       677\n",
      "weighted avg       0.63      0.40      0.39       677\n",
      "\n",
      "--------------------------------------------------\n",
      "F1 Score: 0.44931046181034356\n"
     ]
    }
   ],
   "source": [
    "train_predictions = gs.predict(x_tr)\n",
    "cr = classification_report(y_tr, train_predictions)\n",
    "f1_trained_score = f1_score(y_tr, train_predictions, average = 'macro')\n",
    "print(\"Training Scores:\")\n",
    "print(cr)\n",
    "print(\"-\"*50)\n",
    "print(f\"F1 Score: {f1_trained_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Scores:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         2.0       1.00      0.67      0.80         3\n",
      "         3.0       0.33      0.50      0.40         6\n",
      "         6.0       0.47      0.22      0.30        32\n",
      "         7.0       0.81      0.31      0.45        81\n",
      "         8.0       0.42      0.55      0.48        29\n",
      "        10.0       0.11      0.50      0.17         4\n",
      "        11.0       0.10      0.27      0.14        11\n",
      "        12.0       0.08      0.50      0.14         4\n",
      "\n",
      "   micro avg       0.35      0.35      0.35       170\n",
      "   macro avg       0.41      0.44      0.36       170\n",
      "weighted avg       0.58      0.35      0.40       170\n",
      "\n",
      "--------------------------------------------------\n",
      "F1 Score: 0.3595767591213467\n"
     ]
    }
   ],
   "source": [
    "val_predictions = gs.predict(x_val)\n",
    "cr = classification_report(y_val, val_predictions)\n",
    "f1_trained_score = f1_score(y_val, val_predictions, average = 'macro')\n",
    "print(\"Validation Scores:\")\n",
    "print(cr)\n",
    "print(\"-\"*50)\n",
    "print(f\"F1 Score: {f1_trained_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, on the plus side, the overfitting problem is a lot lower than it was before, but our F1 still took a massive hit. In addition, even though the variance between the sets is lower than it was, the validation F1 in the model that was overfitting still outperformed the validation F1 in this one.\n",
    "\n",
    "So, what are our options? One of the \"go-to\" options for overfitting is to reduce the number of features in the model. A great way of doing this without losing a lot of the variation across the features is to use Principle Component Analysis (PCA)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For now, we are going to stick with the model that has a greater level of overfitting, but performs better on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:    5.9s remaining:    5.9s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    6.2s finished\n",
      "C:\\Users\\reide\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise-deprecating',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
       "            criterion='gini', max_depth=None, max_features='auto',\n",
       "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "            min_impurity_split=None, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators='warn', n_jobs=-1, oob_score=False,\n",
       "            random_state=42, verbose=0, warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=-1,\n",
       "       param_grid={'max_depth': [5], 'n_estimators': [500]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='f1_macro', verbose=2)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_dictionary = {\"max_depth\": [5], 'n_estimators': [500]}\n",
    "clf = RandomForestClassifier(n_jobs=-1, class_weight='balanced', random_state=42)\n",
    "gs = GridSearchCV(clf, param_dictionary, scoring='f1_macro', n_jobs=-1, verbose=2, cv=10)\n",
    "gs.fit(x_tr, y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Scores:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         2.0       1.00      0.89      0.94        27\n",
      "         3.0       0.81      0.84      0.82        25\n",
      "         6.0       0.66      0.47      0.55       159\n",
      "         7.0       0.84      0.56      0.67       403\n",
      "         8.0       0.56      0.82      0.66       128\n",
      "        10.0       0.44      0.80      0.57        30\n",
      "        11.0       0.38      0.75      0.50        44\n",
      "        12.0       0.31      0.87      0.46        31\n",
      "\n",
      "   micro avg       0.63      0.63      0.63       847\n",
      "   macro avg       0.63      0.75      0.65       847\n",
      "weighted avg       0.71      0.63      0.64       847\n",
      "\n",
      "--------------------------------------------------\n",
      "F1 Score: 0.6478939141777655\n"
     ]
    }
   ],
   "source": [
    "train_predictions = gs.predict(X_train)\n",
    "cr = classification_report(y_train, train_predictions)\n",
    "f1_trained_score = f1_score(y_train, train_predictions, average = 'macro')\n",
    "print(\"Training Scores:\")\n",
    "print(cr)\n",
    "print(\"-\"*50)\n",
    "print(f\"F1 Score: {f1_trained_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Scores:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         2.0       1.00      0.67      0.80         6\n",
      "         3.0       0.62      0.71      0.67         7\n",
      "         6.0       0.37      0.32      0.34        31\n",
      "         7.0       0.74      0.45      0.56       124\n",
      "         8.0       0.33      0.59      0.42        22\n",
      "        10.0       0.06      0.17      0.08         6\n",
      "        11.0       0.25      0.62      0.36         8\n",
      "        12.0       0.11      0.25      0.15         8\n",
      "\n",
      "   micro avg       0.45      0.45      0.45       212\n",
      "   macro avg       0.43      0.47      0.42       212\n",
      "weighted avg       0.58      0.45      0.49       212\n",
      "\n",
      "--------------------------------------------------\n",
      "F1 Score: 0.4224341787759474\n"
     ]
    }
   ],
   "source": [
    "val_predictions = gs.predict(X_test)\n",
    "cr = classification_report(y_test, val_predictions)\n",
    "f1_trained_score = f1_score(y_test, val_predictions, average = 'macro')\n",
    "print(\"Validation Scores:\")\n",
    "print(cr)\n",
    "print(\"-\"*50)\n",
    "print(f\"F1 Score: {f1_trained_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
